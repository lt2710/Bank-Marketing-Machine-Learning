---
title: "Predicting academic job salary"
author: "Langyi Tian"
date: "March 2020"
output:
  xaringan::moon_reader:
    css: ["mtheme_max.css", "fonts_mtheme_max.css"]    
    lib_dir: libs
    keep_md: true
    self_contained: false
    nature:
      ratio: 16:9
      highlightStyle: github
      highlightLines: true
editor_options: 
  chunk_output_type: inline
---
exclude: true

class: left, top
background-image: url(images/roadmap.png)
background-size: 100%
background-position: 50% 280%


## Setup
```{r setup, include=FALSE}
rm(list = ls())#clear environment
wd <- "~/GitHub/Pet-projects/vote-analysis/"#set working directory
#Set up default knitr chunk options
library("knitr")
knitr::opts_chunk$set(
  echo = FALSE,
  eval = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.height = 6,
  fig.width = 15,
  fig.align = "center",
  cache = TRUE,
  cache.lazy = FALSE
)
#knitr::opts_knit$set(root.dir = "C:/Users/Tianl/Documents/GitHub/Bank-Marketing-Machine-Learning/Census")
options(htmltools.dir.version = FALSE)
```  

```{r theme-map, include=FALSE}
#set up theme map
theme_simplemap <- function(base_size = 9,
                            base_family = "") {
  theme_bw(base_size = base_size, base_family = base_family) %+replace%
    theme(
      axis.line = element_blank(),
      axis.text = element_blank(),
      axis.ticks = element_blank(),
      axis.title = element_blank(),
      panel.background = element_blank(),
      panel.border = element_blank(),
      panel.grid = element_blank(),
      panel.spacing = unit(0, "lines"),
      plot.background = element_blank(),
      legend.position = "none"
    )
}
```

```{r load packages}
packages <- c(
  "tidyverse",
  "tidymodels",
  "tune",
  "vip",
  "ggplot2",
  "finalfit"
)
packages <- lapply(
  packages,
  FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x)
      library(x, character.only = TRUE)
    }
  }
)
select<-dplyr::select
```

```{r}
#import raw data
dta <- read.csv("Salaries.csv",
                  stringsAsFactors = FALSE)
```

```{r}
#print a summary
summary(dta)
```

---
# Analysis
(1) What percentage of records are Assistant Professors with less than 5 years of experience?
```{r}
cat((nrow(dta%>%filter(rank=="AsstProf",yrs.service<5))*100/nrow(dta))%>%round(2),
    "% of records are Assistant Professors with less than 5 years of experience.",
    sep = "")
```

(2) Is there a statistically significant difference between female and male salaries?

 - Here we want to test the salary against two sex categories. Salary data does not follow a normal distribution in our sample, so we adopt the 2-sample Wilcoxon test. 

.pull-left[
```{r}
dta%>%group_by(sex)%>%summarise(mean(salary))
```
]

.pull-right[
```{r}
wilcox.test(salary~sex,data = dta)
```
]

 - The p-value is smaller than 0.01, strongly against the null hypothesis that male and female holds equal salary. In other words, female and male salaries are significantly different. 

---
# Analysis
(3) What is the distribution of salary by rank and discipline?
```{r,fig.height=3}
rank_plot <- ggplot(dta,
                    aes(x = rank %>% reorder(dta$salary),
                        y = salary)) +
  geom_boxplot(fill = "skyblue2")
discipline_plot <- ggplot(dta,
                          aes(x = discipline %>% reorder(dta$salary),
                              y = salary)) +
  geom_boxplot(fill = "skyblue2")
plot_pretty <- function(plot) {
  pretty_plot <- plot + 
    xlab("") +
    ylab("") +
    theme_classic() +
    theme(text = element_text(size = 15)) 
  return(pretty_plot)
}

grid.arrange(plot_pretty(rank_plot),
             plot_pretty(discipline_plot),
             nrow = 1)
```
 - We can see higher tank is associated with higher salary. Discipline B enjoys more than A. 

(4) How would you recode discipline as a 0/1 binary indicator?

```{r, echo=TRUE}
#a typical way to dummy code to avoid redundancy/collinearity
discipline_B<-(dta$discipline=="B")%>%as.numeric()#will use dplyr::mutate if manipulating a dataframe
```

```{r}
table(discipline_B)#view the result
```

---
exclude: true
```{r}
#inspect missing values
missing_glimpse(dta)
```
---
#Modeling: Data preparation

 - There is no unique id column so we assume there's no duplicates. 
 - The data is complete with no need for missing value imputations
 - Years since phd and years of service is strongly correlated.
```{r}
cor.test(dta$yrs.since.phd, dta$yrs.service, method="pearson")
```
 - We manually construct a variable measuring gap between year of phd graduation and year starting service
 
```{r, echo=TRUE}
dta<-dta%>%mutate(gap=yrs.since.phd-yrs.service)%>%select(-yrs.since.phd)
```
---
#Modeling: Train/test split

 - We don't have many records, so use 80% records to train data 
 - For hyperparameter tuning, we use 5-fold CV inside the training set
 
```{r}
set.seed(1)
#initial 8:2 split betwee train test set
dta_split <- initial_split(dta, prop = .8)
train <- training(dta_split)
test  <- testing(dta_split)
#define 5 fold cv in training set to tune hyperparameters
vfold <- vfold_cv(train, v = 5)
```

 - The preprocessing steps:
```{r}
#modeling framework
formula.reg <- as.formula(salary ~ .)
salary_rec <- recipe(formula.reg,
                     data = train) %>%
  step_log(all_outcomes(), base = 10) %>%
  step_string2factor(all_nominal(),-all_outcomes()) %>%
  step_dummy(all_nominal()) %>%
  step_poly(yrs.service, degree = 2)  %>%
  step_normalize(all_predictors(),-all_nominal())

salary_rec
```

---
#Modeling: Tidymodels framework

 - Start with a penalized regression as baseline. Quick and interpratable. 
 
```{r}
#define glmn model
glmn_model <-
  linear_reg(penalty = tune(), mixture = tune()) %>% 
  set_engine("glmnet") %>%
  set_mode("regression")
glmn_model
```

---
#Modeling: Tuning the best model

 - We use a random grid search for mixture and penalty with 10 levels for each.
 
```{r,results=FALSE}
#define parameter grid
glmn_grid <- glmn_model %>% parameters() %>% grid_regular(levels = c(10,10))
#grid search
glmn_reg_search <-
  tune_grid(salary_rec,
            model = glmn_model,
            resamples = vfold,
            grid = glmn_grid)
show_best(glmn_reg_search, metric = "rmse", maximize = FALSE)
```
 
 
```{r,fig.height=3.5}
rmse_vals <- collect_metrics(glmn_reg_search) %>% filter(.metric == "rmse")
rmse_vals %>% 
  mutate(mixture = format(mixture)) %>% 
  ggplot(aes(x = penalty, y = mean, col = mixture)) + 
  ylab("RMSE") +
  geom_line() + 
  scale_x_log10() + 
  scale_color_brewer() +
  theme_classic() +
  theme(text = element_text(size = 15)) 
```

 - The best model:

```{r}
#inspect the best coefficient
best_glmn <-
  select_best(glmn_reg_search, metric = "rmse", maximize = FALSE)
best_glmn
```
 - The penalty and mixture are relatively small, showing that most variables have good prediction power

---
#Modeling: Variable importance
```{r}
#finalize the recipe
final_rec <- salary_rec %>% prep()
#finalize the best trained glmn model
final_glmn_model <-
  glmn_model %>%
  finalize_model(best_glmn) %>%
  fit(formula.reg, data = juice(final_rec))
```

```{r}
#plot var importance
vip(final_glmn_model,
    fill = "skyblue2")+
  theme_classic() +
  theme(text = element_text(size = 15))
```

 - Being a professor and in discipline B have good prediction power of higher salary.

---
#Modeling: Residual analysis on test set
```{r}
#preprocess the test set using the same recipe
test_baked<-bake(final_rec,test)
#plot residual
test_prediction<-cbind(.pred=predict(final_glmn_model,new_data = test_baked),
                       salary=test_baked$salary)
ggplot(test_prediction, aes(x = .pred, y = salary)) + 
  geom_abline(col = "skyblue2") + 
  geom_point(alpha = .8) + 
  xlab("Predicted value") +
  ylab("Salary") +
  theme_classic() +
  theme(text = element_text(size = 15)) 
```

 - The performance is better at lower side of the salary. It's harder to predict higher salary. 
In a larger workflow, I will use this as a baseline and try a few more models (e.g. tree algorithms which are less sensitive to extreme values). Since this is a showcase example, I'll stop here. 

---
#Modeling (binary classification)
 -
```{r, echo=TRUE}
dta <- dta %>% mutate(salary = (salary > median(dta$salary)) %>% as.numeric()%>% as.factor())
```

```{r}
table(dta$salary)
```

 - Same train/test split
 
```{r}
set.seed(1)
#initial 8:2 split betwee train test set
dta_split <- initial_split(dta, prop = .8)
train <- training(dta_split)
test  <- testing(dta_split)
#define 5 fold cv in training set to tune hyperparameters
vfold <- vfold_cv(train, v = 5)
```

 - Same preprocessing steps

```{r}
#modeling framework
formula.reg <- as.formula(salary ~ .)
salary_rec <- recipe(formula.reg,
                     data = train) %>%
  step_string2factor(all_nominal(),-all_outcomes()) %>%
  step_dummy(all_nominal(),-all_outcomes()) %>%
  step_poly(yrs.service, degree = 2)  %>%
  step_normalize(all_predictors(),-all_nominal())

salary_rec
```

--- 

 - For classification I usually start with logistic regressions as baseline, but since we used glmnet already, let's do a CART instead.
 
```{r}
#define glmn model
cart_model <-
  decision_tree(cost_complexity = tune(), min_n = tune()) %>% 
  set_engine("rpart") %>%
  set_mode("classification")
cart_model 
```

---
#Modeling: Tuning the best model

 - We use a simple grid search for mixture and penalty with 10 levels for each.
 
```{r,results=FALSE}
#define parameter grid
cart_grid <- cart_model %>% parameters() %>% grid_regular(levels = c(5,5))
#grid search
ctrl <- control_grid(save_pred = TRUE)
cart_reg_search <-
  tune_grid(salary_rec,
            model = cart_model,
            resamples = vfold,
            grid = cart_grid,
            control = ctrl)
show_best(cart_reg_search, metric = "roc_auc", maximize = FALSE)
```
 
 
```{r,fig.height=3.5}
best_cart <-
  select_best(cart_reg_search, metric = "roc_auc", maximize = FALSE)

cart_pred <- collect_predictions(cart_reg_search)
cart_pred %>% 
  inner_join(best_cart) %>% 
  mutate(salary=salary%>%as.factor(),
         .pred_class=.pred_class%>%as.numeric()) %>%
  group_by(id) %>% 
  roc_curve(salary, .pred_class) %>% 
  autoplot()
```

 - The best model:

```{r}
#inspect the best coefficient
best_cart
```
 - The penalty and mixture are relatively small, showing that most variables have good prediction power

---
#Modeling: Variable importance
```{r}
#finalize the recipe
final_rec <- salary_rec %>% prep()
#finalize the best trained glmn model
final_cart_model <-
  cart_model %>%
  finalize_model(best_cart) %>%
  fit(formula.reg, data = juice(final_rec))
```

```{r}
#plot var importance
vip(final_cart_model,
    fill = "skyblue2")+
  theme_classic() +
  theme(text = element_text(size = 15))
```

 - Being a professor and in discipline B have good prediction power of higher salary.

---
#Modeling: Residual analysis on test set
```{r}
#preprocess the test set using the same recipe
test_baked <- bake(final_rec, test)
#plot residual
test_prediction <-
  cbind(
    .pred_class = predict(final_cart_model, new_data = test_baked),
    salary = test_baked$salary
  ) %>% mutate(.pred_class = .pred_class %>% as.numeric())
test_prediction %>%
  roc_curve(salary, .pred_class) %>%
  autoplot()
```
 