View(test)
table(dta$salary)
juice(salary_rec)%>%View()
juice(salary_rec%>%prep())%>%View()
salary_rec[[1]]
salary_rec[1]
#define glmn model
glmn_model <-
decsion_tree(min_n = tune()) %>%
set_engine("rpart") %>%
set_mode("classification")
?decsion_tree
??decsion_tree
install.packages("rpart")
install.packages("rpart")
#define glmn model
glmn_model <-
decsion_tree(min_n = tune()) %>%
set_engine("rpart") %>%
set_mode("classification")
library(rpart)
#define glmn model
glmn_model <-
decsion_tree(min_n = tune()) %>%
set_engine("rpart") %>%
set_mode("classification")
?linear_reg
#define glmn model
glmn_model <-
decision_tree(min_n = tune()) %>%
set_engine("rpart") %>%
set_mode("classification")
glmn_model
#define glmn model
glmn_model <-
decision_tree(cost_complexity = tune(), min_n = tune()) %>%
set_engine("rpart") %>%
set_mode("classification")
glmn_model
#define parameter grid
glmn_grid <- glmn_model %>% parameters() %>% grid_regular(levels = c(10,10))
#grid search
glmn_reg_search <-
tune_grid(salary_rec,
model = glmn_model,
resamples = vfold,
grid = glmn_grid)
show_best(glmn_reg_search, metric = "auc", maximize = FALSE)
glmn_grid
#define parameter grid
glmn_grid <- glmn_model %>% parameters() %>% grid_regular(levels = c(10,10))
#grid search
glmn_reg_search <-
tune_grid(salary_rec,
model = glmn_model,
resamples = vfold,
grid = glmn_grid)
show_best(glmn_reg_search, metric = "roc_auc", maximize = FALSE)
glmn_model
glmn_grid
glmn_reg_search <-
tune_grid(salary_rec,
model = glmn_model,
resamples = vfold,
grid = glmn_grid)
dta <- dta %>% mutate(salary = (salary > median(dta$salary)) %>% as.factor())
table(dta$salary)
set.seed(1)
#initial 8:2 split betwee train test set
dta_split <- initial_split(dta, prop = .8)
train <- training(dta_split)
test  <- testing(dta_split)
#define 5 fold cv in training set to tune hyperparameters
vfold <- vfold_cv(train, v = 5)
#modeling framework
formula.reg <- as.formula(salary ~ .)
salary_rec <- recipe(formula.reg,
data = train) %>%
step_string2factor(all_nominal(),-all_outcomes()) %>%
step_dummy(all_nominal()) %>%
step_poly(yrs.service, degree = 2)  %>%
step_normalize(all_predictors(),-all_nominal())
salary_rec
#define glmn model
glmn_model <-
decision_tree(cost_complexity = tune(), min_n = tune()) %>%
set_engine("rpart") %>%
set_mode("classification")
glmn_model
#define parameter grid
glmn_grid <- glmn_model %>% parameters() %>% grid_regular(levels = c(10,10))
#grid search
glmn_reg_search <-
tune_grid(salary_rec,
model = glmn_model,
resamples = vfold,
grid = glmn_grid)
show_best(glmn_reg_search, metric = "roc_auc", maximize = FALSE)
dta$salary
dta$salary%>%table()
tune_grid(salary_rec,
model = glmn_model,
resamples = vfold,
grid = glmn_grid)
dta <- dta %>% mutate(salary = (salary > median(dta$salary)) %>% as.numeric()%>%as.factor)
dta <- dta %>% mutate(salary = (salary > median(dta$salary)) %>% as.numeric()%>%as.factor)
rm(list = ls())#clear environment
wd <- "~/GitHub/Pet-projects/vote-analysis/"#set working directory
#Set up default knitr chunk options
library("knitr")
knitr::opts_chunk$set(
echo = FALSE,
eval = TRUE,
message = FALSE,
warning = FALSE,
fig.height = 6,
fig.width = 15,
fig.align = "center",
cache = TRUE,
cache.lazy = FALSE
)
#knitr::opts_knit$set(root.dir = "C:/Users/Tianl/Documents/GitHub/Bank-Marketing-Machine-Learning/Census")
options(htmltools.dir.version = FALSE)
#set up theme map
theme_simplemap <- function(base_size = 9,
base_family = "") {
theme_bw(base_size = base_size, base_family = base_family) %+replace%
theme(
axis.line = element_blank(),
axis.text = element_blank(),
axis.ticks = element_blank(),
axis.title = element_blank(),
panel.background = element_blank(),
panel.border = element_blank(),
panel.grid = element_blank(),
panel.spacing = unit(0, "lines"),
plot.background = element_blank(),
legend.position = "none"
)
}
packages <- c(
"tidyverse",
"tidymodels",
"tune",
"vip",
"ggplot2",
"finalfit"
)
packages <- lapply(
packages,
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x)
library(x, character.only = TRUE)
}
}
)
select<-dplyr::select
#import raw data
dta <- read.csv("Salaries.csv",
stringsAsFactors = FALSE)
#print a summary
summary(dta)
cat((nrow(dta%>%filter(rank=="AsstProf",yrs.service<5))*100/nrow(dta))%>%round(2),
"% of records are Assistant Professors with less than 5 years of experience.",
sep = "")
dta%>%group_by(sex)%>%summarise(mean(salary))
wilcox.test(salary~sex,data = dta)
rank_plot <- ggplot(dta,
aes(x = rank %>% reorder(dta$salary),
y = salary)) +
geom_boxplot(fill = "skyblue2")
discipline_plot <- ggplot(dta,
aes(x = discipline %>% reorder(dta$salary),
y = salary)) +
geom_boxplot(fill = "skyblue2")
plot_pretty <- function(plot) {
pretty_plot <- plot +
xlab("") +
ylab("") +
theme_classic() +
theme(text = element_text(size = 15))
return(pretty_plot)
}
grid.arrange(plot_pretty(rank_plot),
plot_pretty(discipline_plot),
nrow = 1)
#a typical way to dummy code to avoid redundancy/collinearity
discipline_B<-(dta$discipline=="B")%>%as.numeric()#will use dplyr::mutate if manipulating a dataframe
table(discipline_B)#view the result
#inspect missing values
missing_glimpse(dta)
cor.test(dta$yrs.since.phd, dta$yrs.service, method="pearson")
dta<-dta%>%mutate(gap=yrs.since.phd-yrs.service)%>%select(-yrs.since.phd)
set.seed(1)
#initial 8:2 split betwee train test set
dta_split <- initial_split(dta, prop = .8)
train <- training(dta_split)
test  <- testing(dta_split)
#define 5 fold cv in training set to tune hyperparameters
vfold <- vfold_cv(train, v = 5)
#modeling framework
formula.reg <- as.formula(salary ~ .)
salary_rec <- recipe(formula.reg,
data = train) %>%
step_log(all_outcomes(), base = 10) %>%
step_string2factor(all_nominal(),-all_outcomes()) %>%
step_dummy(all_nominal()) %>%
step_poly(yrs.service, degree = 2)  %>%
step_normalize(all_predictors(),-all_nominal())
salary_rec
#define glmn model
glmn_model <-
linear_reg(penalty = tune(), mixture = tune()) %>%
set_engine("glmnet") %>%
set_mode("regression")
glmn_model
#define parameter grid
glmn_grid <- glmn_model %>% parameters() %>% grid_regular(levels = c(10,10))
#grid search
glmn_reg_search <-
tune_grid(salary_rec,
model = glmn_model,
resamples = vfold,
grid = glmn_grid)
show_best(glmn_reg_search, metric = "rmse", maximize = FALSE)
rmse_vals <- collect_metrics(glmn_reg_search) %>% filter(.metric == "rmse")
rmse_vals %>%
mutate(mixture = format(mixture)) %>%
ggplot(aes(x = penalty, y = mean, col = mixture)) +
ylab("RMSE") +
geom_line() +
scale_x_log10() +
scale_color_brewer() +
theme_classic() +
theme(text = element_text(size = 15))
#inspect the best coefficient
best_glmn <-
select_best(glmn_reg_search, metric = "rmse", maximize = FALSE)
best_glmn
#finalize the recipe
final_rec <- salary_rec %>% prep()
#finalize the best trained glmn model
final_glmn_model <-
glmn_model %>%
finalize_model(best_glmn) %>%
fit(formula.reg, data = juice(final_rec))
#plot var importance
vip(final_glmn_model,
fill = "skyblue2")+
theme_classic() +
theme(text = element_text(size = 15))
#preprocess the test set using the same recipe
test_baked<-bake(final_rec,test)
#plot residual
test_prediction<-cbind(.pred=predict(final_glmn_model,new_data = test_baked),
salary=test_baked$salary)
ggplot(test_prediction, aes(x = .pred, y = salary)) +
geom_abline(col = "skyblue2") +
geom_point(alpha = .8) +
xlab("Predicted value") +
ylab("Salary") +
theme_classic() +
theme(text = element_text(size = 15))
dta <- dta %>% mutate(salary = (salary > median(dta$salary)) %>% as.numeric()%>%as.factor)
table(dta$salary)
dta%>%str()
set.seed(1)
#initial 8:2 split betwee train test set
dta_split <- initial_split(dta, prop = .8)
train <- training(dta_split)
test  <- testing(dta_split)
#define 5 fold cv in training set to tune hyperparameters
vfold <- vfold_cv(train, v = 5)
#modeling framework
formula.reg <- as.formula(salary ~ .)
salary_rec <- recipe(formula.reg,
data = train) %>%
step_string2factor(all_nominal(),-all_outcomes()) %>%
step_dummy(all_nominal(),-all_outcomes()) %>%
step_poly(yrs.service, degree = 2)  %>%
step_normalize(all_predictors(),-all_nominal())
salary_rec
#define glmn model
glmn_model <-
decision_tree(cost_complexity = tune(), min_n = tune()) %>%
set_engine("rpart") %>%
set_mode("classification")
glmn_model
#define parameter grid
glmn_grid <- glmn_model %>% parameters() %>% grid_regular(levels = c(10,10))
#grid search
glmn_reg_search <-
tune_grid(salary_rec,
model = glmn_model,
resamples = vfold,
grid = glmn_grid)
#define parameter grid
glmn_grid <- glmn_model %>% parameters() %>% grid_regular(levels = c(5,5))
#grid search
glmn_reg_search <-
tune_grid(salary_rec,
model = glmn_model,
resamples = vfold,
grid = glmn_grid)
glmn_reg_search <-
tune_grid(salary_rec,
model = glmn_model,
resamples = vfold,
grid = glmn_grid)
show_best(glmn_reg_search, metric = "roc_auc", maximize = FALSE)
cart_reg_search<-glmn_reg_search
names
names(cart_grid)
names(glmn_grid)
cart_vals <- collect_metrics(cart_reg_search) %>% filter(.metric == "roc_auc")
cart_vals %>%
mutate(cost_complexity = format(cost_complexity)) %>%
ggplot(aes(x = min_n, y = mean, col = cost_complexity)) +
ylab("roc_auc") +
geom_line() +
scale_color_brewer() +
theme_classic() +
theme(text = element_text(size = 15))
#inspect the best coefficient
best_cart <-
select_best(cart_reg_search, metric = "roc_auc", maximize = FALSE)
best_cart
#finalize the recipe
final_rec <- salary_rec %>% prep()
#finalize the best trained glmn model
final_cart_model <-
cart_model %>%
finalize_model(best_cart) %>%
fit(formula.reg, data = juice(final_rec))
cart_model<-glmn_model
#plot var importance
vip(final_cart_model,
fill = "skyblue2")+
theme_classic() +
theme(text = element_text(size = 15))
#finalize the recipe
final_rec <- salary_rec %>% prep()
#finalize the best trained glmn model
final_cart_model <-
cart_model %>%
finalize_model(best_cart) %>%
fit(formula.reg, data = juice(final_rec))
#plot var importance
vip(final_cart_model,
fill = "skyblue2")+
theme_classic() +
theme(text = element_text(size = 15))
#preprocess the test set using the same recipe
test_baked<-bake(final_rec,test)
#plot residual
test_prediction<-cbind(.pred=predict(final_cart_model,new_data = test_baked),
salary=test_baked$salary)
ggplot(test_prediction, aes(x = .pred, y = salary)) +
geom_abline(col = "skyblue2") +
geom_point(alpha = .8) +
xlab("Predicted value") +
ylab("Salary") +
theme_classic() +
theme(text = element_text(size = 15))
View(test_prediction)
#preprocess the test set using the same recipe
test_baked<-bake(final_rec,test)
#plot residual
test_prediction<-cbind(.pred_class=predict(final_cart_model,new_data = test_baked),
salary=test_baked$salary)
ggplot(test_prediction, aes(x = .pred_class, y = salary)) +
geom_abline(col = "skyblue2") +
geom_point(alpha = .8) +
xlab("Predicted value") +
ylab("Salary") +
theme_classic() +
theme(text = element_text(size = 15))
test_prediction%>%
roc_curve(score, .pred_great) %>%
autoplot()
test_prediction %>%
roc_curve(score, .pred_class) %>%
autoplot()
test_prediction %>%
roc_curve(salary, .pred_class) %>%
autoplot()
#preprocess the test set using the same recipe
test_baked<-bake(final_rec,test)
#plot residual
test_prediction<-cbind(.pred_class=predict(final_cart_model,new_data = test_baked),
salary=test_baked$salary%>%as.numeric())
test_prediction %>%
roc_curve(salary, .pred_class) %>%
autoplot()
#preprocess the test set using the same recipe
test_baked<-bake(final_rec,test)
#plot residual
test_prediction<-cbind(.pred_class=predict(final_cart_model,new_data = test_baked%>%as.numeric()),
salary=test_baked$salary%>%as.numeric())
#preprocess the test set using the same recipe
test_baked<-bake(final_rec,test)
#plot residual
test_prediction<-cbind(.pred_class=predict(final_cart_model,new_data = test_baked)%>%as.numeric(),
salary=test_baked$salary%>%as.numeric())
#preprocess the test set using the same recipe
test_baked<-bake(final_rec,test)
#plot residual
test_prediction<-cbind(.pred_class=(predict(final_cart_model,new_data = test_baked))%>%as.numeric(),
salary=test_baked$salary%>%as.numeric())
str(test_prediction)
predict(final_cart_model,new_data = test_baked)
predict(final_cart_model,new_data = test_baked)%>%as.numeric()
View(test_prediction)
test_prediction$.pred_class
test_prediction$.pred_class%>%class
test_prediction$.pred_class%>%as.numeric()
#preprocess the test set using the same recipe
test_baked<-bake(final_rec,test)
#plot residual
test_prediction<-cbind(.pred_class=predict(final_cart_model,new_data = test_baked),
salary=test_baked$salary)%>%mutate(.pred_class=.pred_class%>%as.numeric())
test_prediction %>%
roc_curve(salary, .pred_class) %>%
autoplot()
#define parameter grid
cart_grid <- cart_model %>% parameters() %>% grid_regular(levels = c(5,5))
#grid search
ctrl <- control_grid(save_pred = TRUE)
cart_reg_search <-
tune_grid(salary_rec,
model = cart_model,
resamples = vfold,
grid = cart_grid,
control = ctrl)
show_best(cart_reg_search, metric = "roc_auc", maximize = FALSE)
autoplot(cart_reg_search)
#inspect the best coefficient
best_cart <-
select_best(cart_reg_search, metric = "roc_auc", maximize = FALSE)
best_cart
collect_predictions(cart_reg_search)
best_cart <-
select_best(cart_reg_search, metric = "roc_auc", maximize = FALSE)
cart_pred <- collect_predictions(cart_reg_search)
cart_pred %>%
inner_join(best_cart) %>%
group_by(id) %>%
roc_curve(salary, .pred_class) %>%
autoplot()
View(cart_pred)
str(cart_pred)
best_cart <-
select_best(cart_reg_search, metric = "roc_auc", maximize = FALSE)
cart_pred <- collect_predictions(cart_reg_search)
cart_pred %>%
inner_join(best_cart) %>%
mutate(salary=salary%>%as.numeric(),
.pred_class=.pred_class%>%as.numeric())
group_by(id) %>%
roc_curve(salary, .pred_class) %>%
autoplot()
cart_pred %>%
inner_join(best_cart) %>%
mutate(salary=salary%>%as.numeric(),
.pred_class=.pred_class%>%as.numeric())
cart_pred %>%
inner_join(best_cart) %>%
mutate(salary=salary%>%as.numeric(),
.pred_class=.pred_class%>%as.numeric())
group_by(id) %>%
roc_curve(salary, .pred_class)
cart_pred %>%
inner_join(best_cart) %>%
mutate(salary=salary%>%as.numeric(),
.pred_class=.pred_class%>%as.numeric())
group_by(id)
best_cart <-
select_best(cart_reg_search, metric = "roc_auc", maximize = FALSE)
cart_pred <- collect_predictions(cart_reg_search)
cart_pred %>%
inner_join(best_cart) %>%
mutate(salary=salary%>%as.numeric(),
.pred_class=.pred_class%>%as.numeric()) %>%
group_by(id) %>%
roc_curve(salary, .pred_class) %>%
autoplot()
a<-cart_pred %>%
inner_join(best_cart) %>%
mutate(salary=salary%>%as.numeric(),
.pred_class=.pred_class%>%as.numeric())
str(a)
best_cart <-
select_best(cart_reg_search, metric = "roc_auc", maximize = FALSE)
cart_pred <- collect_predictions(cart_reg_search)
cart_pred %>%
inner_join(best_cart) %>%
mutate(salary=salary%>%as.factor(),
.pred_class=.pred_class%>%as.factor()) %>%
group_by(id) %>%
roc_curve(salary, .pred_class) %>%
autoplot()
best_cart <-
select_best(cart_reg_search, metric = "roc_auc", maximize = FALSE)
cart_pred <- collect_predictions(cart_reg_search)
cart_pred %>%
inner_join(best_cart) %>%
mutate(salary=salary%>%as.factor(),
.pred_class=.pred_class%>%as.numeric()) %>%
group_by(id) %>%
roc_curve(salary, .pred_class) %>%
autoplot()
