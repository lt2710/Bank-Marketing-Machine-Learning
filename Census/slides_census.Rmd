---
title: "Predicting subscriptions with bank direct marketing data"
author: "Langyi Tian"
date: "Jan 2020"
output:
  xaringan::moon_reader:
    css: ["default", "default-fonts", "custom_Xaringan.css"]
    lib_dir: libs
    keep_md: true
    self_contained: false
    nature:
      ratio: 16:9
      highlightStyle: github
      highlightLines: true
editor_options: 
  chunk_output_type: inline
---
exclude: true

class: left, top
background-image: url(images/roadmap.png)
background-size: 100%
background-position: 50% 280%

```{r setup, include=FALSE}
#Set up default knitr chunk options
library("knitr")
knitr::opts_chunk$set(
  echo = FALSE,
  eval = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.height = 5,
  fig.width = 12,
  fig.align = "center",
  cache = TRUE,
  cache.lazy = FALSE
)
knitr::opts_knit$set(root.dir = "C:/Users/Tianl/Documents/GitHub/Bank-Marketing-Machine-Learning/Census")
options(htmltools.dir.version = FALSE)
setwd("C:/Users/Tianl/Documents/GitHub/Bank-Marketing-Machine-Learning/Census")
```  

```{r theme-map, include=FALSE}
#set up theme map
theme_simplemap <- function(base_size = 9,
                            base_family = "") {
  theme_bw(base_size = base_size, base_family = base_family) %+replace%
    theme(
      axis.line = element_blank(),
      axis.text = element_blank(),
      axis.ticks = element_blank(),
      axis.title = element_blank(),
      panel.background = element_blank(),
      panel.border = element_blank(),
      panel.grid = element_blank(),
      panel.spacing = unit(0, "lines"),
      plot.background = element_blank(),
      legend.position = "none"
    )
}
```

```{r load packages}
#load packages.
packages <- c(
  "GGally",
  "caret",
  "corrplot",
  "data.table",
  "pROC",
  "tidyverse",
  "stringr",
  "knitr",
  "ggplot2",
  "gridExtra",
  "FactoMineR",
  "factoextra",
  "RColorBrewer"
)
packages <- lapply(
  packages,
  FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x)
      library(x, character.only = TRUE)
    }
  }
)
select<-dplyr::select
```


Before any modeling, the first step is to get an overview of the information and organization of variables in the dataset, based on which we perform basic data cleaning.

We combine the training and test set during this stage and mark the train/test category in case we need to split them later on. 

```{r import data and print summary}
#import raw data
train <- read.csv("adult.data.csv",
                  header = FALSE,
                  stringsAsFactors = FALSE)
test <- read.csv("adult.test.csv",
                 header = FALSE,
                 skip = 1,
                 stringsAsFactors = FALSE)
#combine train and test together
dta <- rbind(cbind(set = rep("train", nrow(train)),
                   train),
             cbind(set = rep("test", nrow(test)),
                   test))
#assign variable names
names(dta)[-1] <- c(
  "age",
  "workingclass",
  "fnlwgt",
  "education",
  "education.num",
  "martial.status",
  "occupation",
  "relationship",
  "race",
  "sex",
  "capital.gain",
  "capital.loss",
  "hours.per.week",
  "native.country",
  "income"
)
str(dta)
```

From the structure of data, the majority of the features are categorical.
We also notice a redundant white space before strings, which we should take care of.
From the documentation, the missing values are coded as ?. We transform it to the standard NA notation for R.
After the basic manipulations, we print a summary to understand statistical distribution of variables.

```{r}
#the weighting should have nothing to do with prediction
dta<-dta%>%select(-fnlwgt)

#trim the white space 
dta <- dta %>% mutate_if(is.character, str_trim)

#recode ? and unknown to NA
dta<-na_if(dta,"?")

#print a summary
library(qwraps2)
options(qwraps2_markup = "markdown")
summary.stats<-summary_table(dta)
summary.stats
```

The purpose of the analysis is not pure prediction, but to find the relationship between variables and extract insights for the general audience. Therefore, the variables need to be engineered so that the information can be understood by a normal reader. 

A characteristics of this dataset is that several variables contain very specific categories with extremely small portions. Such level of details cannot be comprehended by general audience and potential can cause overfitting. Therefore, some categories are binned to simplify the information and potentially reduce overfitting as well.

An alternative way is PCA/MCA on several variables to reduce dimensionality. However, it adds difficulties in explaining things. 



The categories of martial.status, relationship, and sex seem to have overlap in each other. We'd like to try some binning to reduce the redundancy.

```{r}
dta$relationship[dta$relationship%in%c("Husband","Wife")]<-"Married"
```

Country names have too many values and need to be binned.
I recode countries other than the US, Mexico and Phillipines to the corresponding continent. The chi-square wasn't lowered much. 
```{r}
library(countrycode)
library(sjstats)
dta$native.country[!dta$native.country %in% c("United-States")] <-
  countrycode(dta$native.country[!dta$native.country %in% c("United-States")],
              "country.name",
              "continent",
              nomatch = "Not matched")
```

The capital gain/loss might be combined into capital profit 
```{r}
dta<-dta%>%mutate(profit=capital.gain-capital.loss)%>%select(-capital.gain,
                                                             -capital.loss)
```

The income is coded incorrectly. 
```{r}
#recode income
dta$income[dta$income=="<=50K."]<-"<=50K"
dta$income[dta$income==">50K."]<-">50K"
```


Of course, we try to minimize the variance loss during binning. Therefore, we produce contigency tables with chi-square to decide which categories to merge together. 
```{r binning categorical variables and transform some features}
library(sjstats)
#recode character to factor
for (i in names(dta%>%select(-income))){
  if (class(dta[[i]])=="character"){
    i%>%print()
    cramer(as.formula(paste("income~",i,sep = "")),dta)%>%print()
    table(dta[[i]], dta$income)%>%print()
  }
}
```


```{r}
#recode workingclass 
dta$workingclass[dta$workingclass%in%c("Federal-gov","Local-gov","State-gov")]<-"Government"
dta$workingclass[dta$workingclass%in%c("Self-emp-inc","Self-emp-not-inc")]<-"Self-employed"
dta$workingclass[dta$workingclass%in%c("Never-worked","Without-pay")]<-"No work/pay"
#recode martial.status
dta$martial.status[dta$martial.status%in%c("Married-AF-spouse","Married-civ-spouse")]<-"Married"
dta$martial.status[dta$martial.status%in%c("Divorced","Married-spouse-absent","Separated","Widowed")]<-"post-marriage"
#Race
dta$race[dta$race%in%c("Amer-Indian-Eskimo","Asian-Pac-Islander")]<-"Other"
```

Next, we'd deal with the missing values in the data.
```{r print missing value summary}
library(finalfit)
ff_glimpse(dta)
```
Three factors contain missing values. We'd like to see whether the missing can be by random or not, so that we can decide about ways to impute them.

```{r observe pattern of missingness}
dta %>% select(workingclass, occupation, native.country) %>% missing_pattern()
```

The missingness in workingclass and occupation highly correlates with each other. We should guess whether it's MAR or MNAR

```{r}
dta %>% missing_compare("workingclass",
                        c("age", "education.num", "profit"))
```

The missingness in working-related information seems not by random. Those missing the information tend to be older, receive less education, be less active in investment activities. Therefore, we recode the missing value with "missing" label

```{r}
dta$workingclass[is.na(dta$workingclass)==TRUE]<-"missing"
dta$occupation[is.na(dta$occupation)==TRUE]<-"missing"
```

```{r}
#recode character to factor
for (i in names(dta)){
  if (class(dta[[i]])=="character"){
    dta[[i]]<-dta[[i]]%>%as.factor()
  }
}
```


#EDA: segmentation
What attributes are associated with higher income? 
The variables in this data are mostly categorical. The way to understand the relationship between variables are thus different from the continous variable case. 

Unlike dataset where we can produce a correlation matrix, it's not easy to understand the relationship between categorical and numeric features in mixed data. Since the majority of features in this data are categorical, we create from the few numeric features categorical variables and visualize the relationship between them with MCA, a principle component technique on categorical variables. This method might lose some information when we recode numeric features to categorical variable, but is very beneficial for visualizing the relationships of variables in a multi-variate setting.

```{r}
summary.stats<-cbind(summary_table(dta%>%filter(income=="<=50K")),
                     summary_table(dta%>%filter(income==">50K"))
                     )
summary.stats
```

```{r recode}
dta$education.group<-dta$education.num%>%cut(c(-Inf,5,9,12,13,Inf),
                                             labels = c("middle school",
                                                        "high school",
                                                        "associate",
                                                        "bachelor",
                                                        "master"
                                                        ))
dta$age.group<-dta$age%>%cut(c(-Inf,25,40,55,Inf),
                             labels = c("<25 yrs old",
                                        "25-40 yrs old",
                                        "40-55 yrs old",
                                        ">55 yrs old"))
dta$hours.group<-dta$hours.per.week%>%cut(c(-Inf,39,40,Inf),
                                          labels = c("work undertime",
                                                     "work regular hours",
                                                     "work overtime"),)
dta$profit.group<-dta$profit%>%cut(c(-Inf,-1,0,Inf),
                                   labels = c("has investment",
                                              "no investment",
                                              "has investment"))
```

Because occupation variable contains many categories and there's not a very efficient way to recode them, we didn't include it in the analysis. All other variables are included. 

```{r}
library("FactoMineR")
library("factoextra")
dta_famd <-
  dta %>%  select_if(is.factor) %>% filter(!race %in% c("Other"),!native.country %in%
                                             c("Not matched")) %>% select(sex,
                                                                          education.group,
                                                                          race,
                                                                          martial.status,
                                                                          income,
                                                                          native.country,
                                                                          age.group,
                                                                          hours.group,
                                                                          profit.group,
                                                                          workingclass
                                                                          )

res.famd <- FAMD (dta_famd,
                  ncp = 2,
                  ind.sup = NULL,
                  graph = FALSE)

quali.var <- get_famd_var(res.famd, "quali.var")
fviz_famd_var(
  res.famd,
  "quali.var",
  repel = TRUE,
  col.var = "contrib",
  gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
)
```

Follow with K-means on returned clusters

#Modeling
Not only do we want to understand the relationship between income category and other variables, we'd also want to provide a ceteris paribus condition with regression analysis. Because of a lot of categorical variables in the data, overfitting can be easy. Therefore, although the purpose is prediction, we use cross-validation to conduct the analysis. Moreover, by using LASSO, we can select features. 

```{r}
library(tidymodels)
library(parsnip)
train<-dta%>%filter(set=="train")%>%select(-set)
test<-dta%>%filter(set=="test")%>%select(-set)
```

```{r}
formula.1<-formula(income ~ 
            age+
            workingclass+
            education.num+
            martial.status+
            occupation+
            relationship+
            race+
            sex+
            hours.per.week+
            native.country+
            profit)

recipe_simple <- function(dataset) {
  recipe(formula.1, 
         data = dataset) %>%
    step_string2factor(all_nominal(), -all_outcomes()) %>%
    prep(data = dataset)
}

recipe_prepped <- recipe_simple(dataset = train)

train_baked <- bake(recipe_prepped, new_data = train)
test_baked  <- bake(recipe_prepped, new_data = test)
```

```{r}
logistic_glm <-
  logistic_reg(mode = "classification") %>%
  set_engine("glm") %>%
  fit(formula.1, data = train_baked)
```

```{r}
logistic_glm$fit%>%summary()
```

```{r}
predictions_glm <- logistic_glm %>%
  predict(new_data = test_baked) %>%
  bind_cols(test_baked %>% select(income))

predictions_glm %>%
  conf_mat(income,.pred_class) %>%
  pluck(1) %>%
  as_tibble() %>%
  ggplot(aes(Prediction, Truth, alpha = n)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = n), colour = "white", alpha = 1, size = 8)
```

```{r}
predictions_glm %>%
  metrics(income, .pred_class) %>%
  select(-.estimator) %>%
  filter(.metric == "accuracy") 
```

---
##Project summary

 - Mission: Predicting client subscription to a term product
 
 - Data: Direct marketing campaign results

 - Exploratory data analysis:
 
MCA with categorical variables, correlation matrix and PCA with numerics

 - Data preprocessing:
 
Missing value imputation, one hot encoding, scaling, train/test split, under-sampling training set

 - Model training and comparison:
 
Logistic regression, support vector machine, random forest

 - Model selection:
 
Random forest (82% accuracy without hyperparameter tuning)
 
 - Future use cases:

1. Customer portraits supporting target marketing
2. Predictive information product for campaign operations





 - strategy: just do all categorical
